{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bcb426",
   "metadata": {},
   "source": [
    "Cell 1: Imports + constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64000567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Constants\n",
    "PATCH_SIZE = 64\n",
    "STRIDE = 64  # start with no-overlap. later you can try 32 for overlap.\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Inference preprocessing: must match training\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),  # scales [0,255] -> [0,1]\n",
    "    transforms.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd19b9a",
   "metadata": {},
   "source": [
    "Cell 2: Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3765674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Load model (matches Notebook 03 setup)\n",
    "\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "from src.dataset import load_eurosat_dataset\n",
    "from src.models import build_model\n",
    "\n",
    "# Resolve project root + make src importable\n",
    "PROJECT_ROOT = Path(os.getcwd()).resolve()\n",
    "if PROJECT_ROOT.name == \"notebooks\":\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"Project root:\", PROJECT_ROOT)\n",
    "\n",
    "# Use the same device variable everywhere\n",
    "device = DEVICE  # uses DEVICE from Cell 1\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Data dir (same as Notebook 03)\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"raw\" / \"EuroSAT_RGB\"\n",
    "print(\"Data dir:\", DATA_DIR)\n",
    "\n",
    "# Checkpoint \n",
    "models_dir = PROJECT_ROOT / \"models\"\n",
    "MODEL_PATH = models_dir / \"resnet18_pre_ft_best.pth\"   # fine-tuned best\n",
    "\n",
    "if not MODEL_PATH.exists():\n",
    "    print(\"Missing checkpoint:\", MODEL_PATH)\n",
    "    print(\"Available .pth files:\")\n",
    "    for p in sorted(models_dir.glob(\"*.pth\")):\n",
    "        print(\" -\", p.name)\n",
    "    raise FileNotFoundError(f\"Checkpoint not found: {MODEL_PATH}\")\n",
    "\n",
    "# Get class_names (only to set num_classes correctly) \n",
    "_, _, _, class_names = load_eurosat_dataset(\n",
    "    data_dir=DATA_DIR,\n",
    "    img_size=64,\n",
    "    batch_size=64,\n",
    "    seed=42,\n",
    "    aug_level=\"light\",\n",
    ")\n",
    "\n",
    "print(\"Num classes:\", len(class_names))\n",
    "print(\"Classes:\", class_names)\n",
    "\n",
    "# Build model architecture and load weights \n",
    "model = build_model(\n",
    "    num_classes=len(class_names),\n",
    "    model_name=\"resnet18\",\n",
    "    pretrained=True,\n",
    "    freeze_backbone=False,\n",
    ").to(device)\n",
    "\n",
    "state = torch.load(MODEL_PATH, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "print(\"Loaded checkpoint:\", MODEL_PATH.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd9847",
   "metadata": {},
   "source": [
    "Cell 3: Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb861e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_patch(pil_patch: Image.Image):\n",
    "    \"\"\"\n",
    "    pil_patch: PIL Image (64x64, RGB)\n",
    "    returns: (pred_class:int, probs:np.ndarray)\n",
    "    \"\"\"\n",
    "    x = preprocess(pil_patch).unsqueeze(0).to(DEVICE)  # (1,3,64,64)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        probs = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "        pred = int(np.argmax(probs))\n",
    "\n",
    "    return pred, probs\n",
    "\n",
    "# Quick test\n",
    "test_patch = Image.open(\"path/to/some_small_tile.png\").convert(\"RGB\").resize((64, 64))\n",
    "pred, probs = predict_patch(test_patch)\n",
    "\n",
    "print(\"Pred:\", pred)\n",
    "print(\"Top prob:\", float(probs[pred]))\n",
    "print(\"Probs shape:\", probs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6dbd6b",
   "metadata": {},
   "source": [
    "Cell 4: Tiling a large image into a prediction grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e42bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_multiple(img: Image.Image, multiple: int):\n",
    "    w, h = img.size\n",
    "    new_w = int(math.ceil(w / multiple) * multiple)\n",
    "    new_h = int(math.ceil(h / multiple) * multiple)\n",
    "\n",
    "    if new_w == w and new_h == h:\n",
    "        return img, (0, 0)\n",
    "\n",
    "    padded = Image.new(\"RGB\", (new_w, new_h))\n",
    "    padded.paste(img, (0, 0))\n",
    "    return padded, (new_w - w, new_h - h)\n",
    "\n",
    "\n",
    "def sliding_window_predict(image_path: str, patch_size=64, stride=64, return_confidence=False):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img, pad = pad_to_multiple(img, patch_size)\n",
    "\n",
    "    w, h = img.size\n",
    "    cols = (w - patch_size) // stride + 1\n",
    "    rows = (h - patch_size) // stride + 1\n",
    "\n",
    "    pred_grid = np.zeros((rows, cols), dtype=np.int32)\n",
    "    conf_grid = None\n",
    "\n",
    "    if return_confidence:\n",
    "        pass\n",
    "\n",
    "    if return_confidence:\n",
    "        first_patch = img.crop((0, 0, patch_size, patch_size))\n",
    "        _, probs = predict_patch(first_patch)\n",
    "        num_classes = probs.shape[0]\n",
    "        conf_grid = np.zeros((rows, cols, num_classes), dtype=np.float32)\n",
    "\n",
    "    for r in range(rows):\n",
    "        y = r * stride\n",
    "        for c in range(cols):\n",
    "            x = c * stride\n",
    "            patch = img.crop((x, y, x + patch_size, y + patch_size))\n",
    "            pred, probs = predict_patch(patch)\n",
    "\n",
    "            pred_grid[r, c] = pred\n",
    "            if return_confidence:\n",
    "                conf_grid[r, c, :] = probs\n",
    "\n",
    "    meta = {\n",
    "        \"orig_size\": Image.open(image_path).size,\n",
    "        \"padded_size\": (w, h),\n",
    "        \"pad_added\": pad,\n",
    "        \"patch_size\": patch_size,\n",
    "        \"stride\": stride,\n",
    "        \"rows\": rows,\n",
    "        \"cols\": cols\n",
    "    }\n",
    "\n",
    "    return pred_grid, conf_grid, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d3983",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = \"path/to/large_satellite.png\"\n",
    "\n",
    "pred_grid, conf_grid, meta = sliding_window_predict(\n",
    "    IMAGE_PATH,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    stride=STRIDE,\n",
    "    return_confidence=True\n",
    ")\n",
    "\n",
    "print(meta)\n",
    "print(\"pred_grid shape:\", pred_grid.shape)\n",
    "print(\"conf_grid shape:\", None if conf_grid is None else conf_grid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00523a80",
   "metadata": {},
   "source": [
    "Cell 5: Quick visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b539e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(pred_grid)\n",
    "plt.title(\"Prediction Grid (class indices)\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
